{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a890af24",
   "metadata": {},
   "source": [
    "## Exercise: Sound detection and localisation\n",
    "Implementation of an algorithm to detect and localise 2 sound events within a 3-channel audio file recorded by 3 sample-synchronized microphones in a known configuration. Event detections are computed using a simple energy threshold metric. Event locations are estimated using TDOA derived from the generalized cross-correlation phase transform (GCC-PHAT), computed over a single static event frame. See README for additional notes and references.\n",
    "\n",
    "Gershon Dublon, 2021-09-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b8f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb7af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read wav files\n",
    "evaluation_recording, fs = sf.read('resources/evaluation-recording.wav')\n",
    "test_recording, fs = sf.read('resources/test-recording.wav')\n",
    "target, fs = sf.read('resources/target.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047623ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the scene \n",
    "\n",
    "# choose which recording to use from the cell above\n",
    "recording = evaluation_recording\n",
    "\n",
    "# speed of sound at 25c\n",
    "c = 346.3\n",
    "\n",
    "# microphone positions (ordered)\n",
    "mics = [(-0.5, 0), (0, 0), (0.5, 0)]\n",
    "\n",
    "# assignment of microphones as reference or measurement, can be swapped around\n",
    "# assignments index into the microphone positions array above\n",
    "ref = 1\n",
    "m1 = 0\n",
    "m2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7727131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to detect event onsets in a mono audio recording\n",
    "# slides non-overlapping windows of window_length over the recording\n",
    "# computes a ratio of the energy in a given frequency band to total energy\n",
    "# if the ratio exceeds a hard threshold, records an onset and jumps forward 2 window_lengths (ignores brief pauses)\n",
    "# will not record another onset until envelope is marked complete\n",
    "def pseudo_vad(recording, fs=44100, window_length=11025, f_low=100, f_high=3000, detection_threshold=0.5):\n",
    "    recording_length = recording.shape[0]\n",
    "    \n",
    "    # frequency band of interest\n",
    "    freqs = np.fft.fftfreq(window_length, 1/fs)\n",
    "    activebands = np.where(np.logical_and(freqs>=f_low, freqs<=f_high))[0]\n",
    "\n",
    "    detections = []\n",
    "    detection_in_progress = False\n",
    "    window_start = 0\n",
    "    while (window_start < (recording_length - window_length)):\n",
    "        # assumes mono audio\n",
    "        sig = recording[window_start:window_start + window_length]\n",
    "        sig_fft = np.abs(np.fft.rfft(sig, n=window_length))\n",
    "\n",
    "        ratio = np.sum(sig_fft[activebands])/np.sum(sig_fft)\n",
    "        if(ratio>detection_threshold):\n",
    "            if not detection_in_progress:\n",
    "                detections.append([window_start,window_start]) # record onset, begin looking for end\n",
    "                detection_in_progress = True\n",
    "            window_start = window_start + 2*window_length # jump forward by 2 windows\n",
    "            # close out cases where a detection is ongoing near the end of the recording:\n",
    "            if(window_start > recording_length - window_length):\n",
    "                detections[len(detections)-1][1]=recording_length\n",
    "                detection_in_progress = False\n",
    "        else:\n",
    "            if detection_in_progress:\n",
    "                detections[len(detections)-1][1]=window_start # record end as 1 window back\n",
    "                detection_in_progress = False\n",
    "            window_start = window_start + window_length\n",
    "\n",
    "    return np.array(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b356b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the generalized cross-correlation phase transform (GCC-PHAT)\n",
    "# to return the offset (in seconds) between correlated signals sig and sigref\n",
    "def gcc_phat(sig, sigref, fs):    \n",
    "    # FFT length\n",
    "    n = sig.shape[0] + sigref.shape[0]\n",
    "    \n",
    "    # FTT input signals\n",
    "    sig_fft = np.fft.rfft(sig, n=n)\n",
    "    sigref_fft = np.fft.rfft(sigref, n=n)\n",
    "    \n",
    "    # GCC-PHAT core\n",
    "    p = sig_fft * np.conj(sigref_fft)\n",
    "    phat = p / np.abs(p)\n",
    "    rphat = np.fft.irfft(phat, n=n)\n",
    "    \n",
    "    # we will consider offsets over the entire input frame valid\n",
    "    # someday we may want to limit this to a plausible range\n",
    "    max_offset = int(n / 2)\n",
    "    rphat = np.concatenate((rphat[-max_offset:], rphat[:max_offset]))\n",
    "    \n",
    "    # works for the example, but garbage in = garbage out here\n",
    "    # in the future, we may want to look into the underlying gcc data\n",
    "    offset = np.argmax(np.abs(rphat)) - max_offset\n",
    "    \n",
    "    # convert offset from samples to seconds\n",
    "    tau = offset / fs\n",
    "    \n",
    "    return tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee00edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system of equations to be solved in order to find the intersection of two hyperbolas\n",
    "def hypers(est_pos, *args):\n",
    "    tau_m1, tau_m2, c, mics, m1, m2, ref = args\n",
    "    x = est_pos[0]\n",
    "    y = est_pos[1]\n",
    "    \n",
    "    r_ref = (mics[ref][0]-x)**2 + (mics[m1][1]-y)**2\n",
    "    r_m1 = (mics[m1][0] - x)**2 + (mics[m1][1] - y)**2\n",
    "    r_m2 = (mics[m2][0] - x)**2 + (mics[m2][1] - y)**2\n",
    "    deltr_m1 = c*tau_m1\n",
    "    deltr_m2 = c*tau_m2\n",
    "    \n",
    "    F = np.empty((2))\n",
    "    F[0] = deltr_m1**2 + 2*deltr_m1*np.sqrt(r_ref) + r_ref - r_m1\n",
    "    F[1] = deltr_m2**2 + 2*deltr_m2*np.sqrt(r_ref) + r_ref - r_m2\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c59d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc367b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run event detection on the given recording\n",
    "detections = pseudo_vad(recording[:,1], fs=44100, window_length=11025, f_low=100, f_high=3000, detection_threshold=0.5)\n",
    "\n",
    "# notebook only: plotting code and terms\n",
    "x = np.linspace(-2, 2, 400)\n",
    "y = np.linspace(0, 3, 400) # given: everything is in front of the array\n",
    "x, y = np.meshgrid(x, y)\n",
    "r_ref = (mics[ref][0]-x)**2 + (mics[m1][1]-y)**2\n",
    "r_m1 = (mics[m1][0] - x)**2 + (mics[m1][1] - y)**2\n",
    "r_m2 = (mics[m2][0] - x)**2 + (mics[m2][1] - y)**2\n",
    "\n",
    "event_count = 0\n",
    "for det in detections:\n",
    "    event_count = event_count + 1\n",
    "    tau_m1 = gcc_phat(recording[det[0]:det[1],m1],recording[det[0]:det[1],ref], fs)\n",
    "    tau_m2 = gcc_phat(recording[det[0]:det[1],m2],recording[det[0]:det[1],ref], fs)\n",
    "    \n",
    "    # notebook only: plotting code and terms\n",
    "    deltr_m1 = c*tau_m1\n",
    "    deltr_m2 = c*tau_m2\n",
    "    plt.figure()\n",
    "    plt.contour(x , y, \n",
    "            deltr_m1**2 + 2*deltr_m1*np.sqrt(r_ref) + r_ref - r_m1,\n",
    "            [0],\n",
    "            colors='b')\n",
    "    plt.contour(x , y, \n",
    "            deltr_m2**2 + 2*deltr_m2*np.sqrt(r_ref) + r_ref - r_m2,\n",
    "            [0],\n",
    "            colors='g')\n",
    "    plt.xlabel('meters')\n",
    "    plt.ylabel('meters')\n",
    "    plt.title('Event {}, t={}s'.format(event_count, det[0]/fs))\n",
    "    \n",
    "    guess = np.array([1,1])\n",
    "    args = (tau_m1, tau_m2, c, mics, m1, m2, ref)\n",
    "    est_loc = fsolve(hypers, guess, args=args)\n",
    "    est_loc = np.around(est_loc, 1)\n",
    "    print('Event {} detected at time {}s, estimated location ({}, {}) meters'.format(event_count, det[0]/fs, est_loc[0], est_loc[1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d859198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
